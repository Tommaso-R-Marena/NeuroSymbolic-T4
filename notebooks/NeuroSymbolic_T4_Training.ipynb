{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"title"},"source":["# NeuroSymbolic-T4: Complete Training Pipeline\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tommaso-R-Marena/NeuroSymbolic-T4/blob/main/notebooks/NeuroSymbolic_T4_Training.ipynb)\n","\n","**Complete end-to-end training on real datasets with automatic downloading**\n","\n","## üìã Contents\n","\n","1. **Setup** - GPU check and installation\n","2. **Dataset Download** - Automatic CLEVR download\n","3. **Model Initialization** - Enhanced architecture\n","4. **Training** - Full training loop with WandB\n","5. **Evaluation** - Comprehensive metrics\n","6. **Export Results** - Save model and figures\n","\n","**Features**: Automatic dataset download, mixed precision training, curriculum learning, WandB logging"]},{"cell_type":"markdown","metadata":{"id":"setup"},"source":["## 1. Setup and Installation"]},{"cell_type":"code","metadata":{"id":"check-gpu"},"source":["# Verify T4 GPU\n","!nvidia-smi\n","\n","import torch\n","print(f\"\\n{'='*60}\")\n","print(\"SYSTEM INFORMATION\")\n","print('='*60)\n","print(f\"PyTorch: {torch.__version__}\")\n","print(f\"CUDA: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n","print('='*60)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"install"},"source":["# Clone and install\n","!git clone https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4.git\n","%cd NeuroSymbolic-T4\n","!pip install -q -r requirements.txt\n","!pip install -q wandb\n","\n","print(\"\\n‚úÖ Installation complete!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"download"},"source":["## 2. Automatic Dataset Download\n","\n","Downloads CLEVR mini (1.5GB) for fast training."]},{"cell_type":"code","metadata":{"id":"download-dataset"},"source":["import sys\n","import os\n","\n","# Check disk space\n","import shutil\n","stat = shutil.disk_usage('.')\n","print(f\"Available disk space: {stat.free/1e9:.1f}GB\")\n","\n","# Download CLEVR mini\n","print(\"\\nDownloading CLEVR (mini subset for fast training)...\")\n","print(\"Estimated size: ~1.5GB\")\n","print(\"This will take 5-10 minutes\\n\")\n","\n","!python benchmarks/download_datasets.py --dataset clevr_mini --data-root ./data\n","\n","print(\"\\n‚úÖ Dataset ready!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"init"},"source":["## 3. Model Initialization"]},{"cell_type":"code","metadata":{"id":"init-model"},"source":["import torch\n","import numpy as np\n","from pathlib import Path\n","import json\n","\n","from neurosymbolic import NeurosymbolicSystem\n","\n","# Configuration\n","config = {\n","    'backbone': 'efficientnet_b0',\n","    'feature_dim': 512,\n","    'num_concepts': 100,\n","    'batch_size': 32,\n","    'epochs': 20,\n","    'lr': 1e-3,\n","    'use_amp': True,\n","    'use_wandb': False,  # Set to True to enable WandB logging\n","}\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","# Initialize model\n","model = NeurosymbolicSystem(\n","    perception_config={\n","        'backbone': config['backbone'],\n","        'feature_dim': config['feature_dim'],\n","        'num_concepts': config['num_concepts'],\n","    }\n",").to(device)\n","\n","print(f\"\\nModel: {sum(p.numel() for p in model.parameters())/1e6:.1f}M parameters\")\n","print(f\"Concepts: {len(model.concept_names)}\")\n","print(f\"Rules: {len(model.reasoner.rules)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"train-header"},"source":["## 4. Training\n","\n","Full training with mixed precision and progress tracking."]},{"cell_type":"code","metadata":{"id":"train"},"source":["# Optional: Login to WandB\n","if config['use_wandb']:\n","    import wandb\n","    wandb.login()\n","    wandb.init(project='neurosymbolic-t4-icml', config=config)\n","\n","# Build training command\n","cmd = [\n","    'python train_benchmarks.py',\n","    '--dataset clevr',\n","    '--clevr-root ./data/CLEVR_mini',\n","    f'--batch-size {config[\"batch_size\"]}',\n","    f'--epochs {config[\"epochs\"]}',\n","    f'--lr {config[\"lr\"]}',\n","    '--use-amp' if config['use_amp'] else '',\n","    '--output-dir ./checkpoints',\n","    '--save-interval 5',\n","]\n","\n","# Join and run\n","cmd_str = ' '.join(filter(None, cmd))\n","print(f\"Running: {cmd_str}\\n\")\n","!{cmd_str}\n","\n","print(\"\\n‚úÖ Training complete!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eval-header"},"source":["## 5. Evaluation\n","\n","Load best model and evaluate performance."]},{"cell_type":"code","metadata":{"id":"eval"},"source":["import torch\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import json\n","\n","# Load best checkpoint\n","checkpoint_path = Path('./checkpoints/best_model.pt')\n","\n","if checkpoint_path.exists():\n","    print(\"Loading best model...\")\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    \n","    print(f\"\\nBest model from epoch {checkpoint.get('epoch', 'unknown')}\")\n","    print(f\"Val loss: {checkpoint['val_metrics']['val_loss']:.4f}\")\n","    print(f\"Avg concepts: {checkpoint['val_metrics']['avg_concepts']:.2f}\")\n","    print(f\"Avg facts derived: {checkpoint['val_metrics']['avg_facts_derived']:.2f}\")\n","else:\n","    print(\"‚ö†Ô∏è No checkpoint found. Using current model.\")\n","\n","# Load training history\n","history_path = Path('./checkpoints/training_history.json')\n","if history_path.exists():\n","    with open(history_path) as f:\n","        history = json.load(f)\n","    \n","    # Plot training curves\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n","    \n","    # Loss curve\n","    ax = axes[0]\n","    ax.plot(history['train_loss'], label='Train Loss', linewidth=2)\n","    ax.plot([m['val_loss'] for m in history['val_metrics']], label='Val Loss', linewidth=2)\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Loss')\n","    ax.set_title('Training & Validation Loss')\n","    ax.legend()\n","    ax.grid(alpha=0.3)\n","    \n","    # Concepts detected\n","    ax = axes[1]\n","    ax.plot([m['avg_concepts'] for m in history['val_metrics']], linewidth=2, color='steelblue')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Avg Concepts')\n","    ax.set_title('Concept Detection Over Training')\n","    ax.grid(alpha=0.3)\n","    \n","    # Facts derived\n","    ax = axes[2]\n","    ax.plot([m['avg_facts_derived'] for m in history['val_metrics']], linewidth=2, color='coral')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Avg Facts Derived')\n","    ax.set_title('Reasoning Depth Over Training')\n","    ax.grid(alpha=0.3)\n","    \n","    plt.tight_layout()\n","    plt.savefig('./checkpoints/training_curves.png', dpi=300, bbox_inches='tight')\n","    print(\"\\n‚úì Saved training curves\")\n","    plt.show()\n","\n","print(\"\\n‚úÖ Evaluation complete!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"benchmark-header"},"source":["## 6. Performance Benchmarking\n","\n","Test inference speed on T4 GPU."]},{"cell_type":"code","metadata":{"id":"benchmark"},"source":["import time\n","from tqdm.notebook import tqdm\n","\n","model.eval()\n","\n","print(\"Benchmarking inference speed...\\n\")\n","\n","# Warmup\n","for _ in range(10):\n","    x = torch.randn(1, 3, 224, 224).to(device)\n","    with torch.no_grad():\n","        _ = model.forward(x)\n","\n","# Benchmark\n","times = []\n","for _ in tqdm(range(100), desc=\"Inference\"):\n","    x = torch.randn(1, 3, 224, 224).to(device)\n","    \n","    torch.cuda.synchronize()\n","    start = time.time()\n","    \n","    with torch.no_grad():\n","        output = model.forward(x, threshold=0.5)\n","    \n","    torch.cuda.synchronize()\n","    times.append(time.time() - start)\n","\n","# Results\n","mean_time = np.mean(times) * 1000\n","std_time = np.std(times) * 1000\n","fps = 1.0 / np.mean(times)\n","\n","print(f\"\\n{'='*50}\")\n","print(\"T4 GPU PERFORMANCE\")\n","print('='*50)\n","print(f\"Mean latency: {mean_time:.2f}¬±{std_time:.2f}ms\")\n","print(f\"Throughput:   {fps:.1f} FPS\")\n","print(f\"GPU Memory:   {torch.cuda.max_memory_allocated()/1e9:.2f}GB\")\n","print('='*50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"export-header"},"source":["## 7. Export Results\n","\n","Save model and results to Google Drive."]},{"cell_type":"code","metadata":{"id":"export"},"source":["# Mount Google Drive\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    \n","    import shutil\n","    \n","    output_dir = '/content/drive/MyDrive/NeuroSymbolic_Training_Results'\n","    Path(output_dir).mkdir(exist_ok=True)\n","    \n","    # Copy files\n","    files_to_copy = [\n","        './checkpoints/best_model.pt',\n","        './checkpoints/training_history.json',\n","        './checkpoints/training_curves.png',\n","        './checkpoints/args.json',\n","    ]\n","    \n","    for file in files_to_copy:\n","        if Path(file).exists():\n","            shutil.copy(file, output_dir)\n","            print(f\"‚úì Copied {Path(file).name}\")\n","    \n","    print(f\"\\n‚úÖ Results saved to: {output_dir}\")\n","    \n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not save to Drive: {e}\")\n","    print(\"Files are still available locally in ./checkpoints/\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"conclusion"},"source":["## üéì Training Complete!\n","\n","### What Was Accomplished:\n","\n","‚úÖ Downloaded and preprocessed CLEVR dataset  \n","‚úÖ Trained neurosymbolic model for 20 epochs  \n","‚úÖ Mixed precision training with gradient clipping  \n","‚úÖ Comprehensive evaluation metrics  \n","‚úÖ Performance benchmarking on T4 GPU  \n","‚úÖ Exported results to Google Drive  \n","\n","### Next Steps:\n","\n","1. **Train longer**: Increase epochs to 30-50 for better convergence\n","2. **Try full CLEVR**: Use `--dataset clevr` instead of `clevr_mini`\n","3. **Add VQA/GQA**: Download and train on additional datasets\n","4. **Hyperparameter tuning**: Experiment with learning rate, batch size\n","5. **Submit to ICML**: Use these results in your paper!\n","\n","---\n","\n","**Repository**: [github.com/Tommaso-R-Marena/NeuroSymbolic-T4](https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4)"]}]}