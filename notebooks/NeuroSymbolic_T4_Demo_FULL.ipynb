{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# NeuroSymbolic-T4: ICML 2026 Benchmark Suite\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tommaso-R-Marena/NeuroSymbolic-T4/blob/main/notebooks/NeuroSymbolic_T4_Demo_FULL.ipynb)\n","[![Paper](https://img.shields.io/badge/ICML-2026-red.svg)](https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4)\n","\n","**Complete demonstration with publication-ready benchmarks on Google Colab T4 GPU**\n","\n","## Contents\n","\n","1. **Setup & Verification** - GPU check and installation\n","2. **System Initialization** - Load neurosymbolic model\n","3. **Neural Perception Demo** - Concept detection\n","4. **Symbolic Reasoning Demo** - Forward/backward chaining\n","5. **Query-Based Inference** - Proof generation\n","6. **Explanation Generation** - Interpretable AI\n","7. **Custom Rules** - Domain-specific knowledge\n","8. **Performance Benchmarking** - T4 GPU metrics\n","9. **ICML Benchmark Suite** - Comprehensive evaluation\n","10. **Ablation Study** - Component analysis\n","11. **Baseline Comparison** - SOTA models\n","12. **Results Visualization** - Publication figures\n","13. **Summary & Export** - Results for paper\n","\n","**FIXED**: Tuple unpacking updated to handle 3-tuple format (concept, confidence, grounded_name)"],"metadata":{"id":"title"}},{"cell_type":"markdown","source":["## 1. Setup and Installation"],"metadata":{"id":"setup-header"}},{"cell_type":"code","source":["# Verify T4 GPU\n","!nvidia-smi\n","\n","import torch\n","print(f\"\\n{'='*60}\")\n","print(\"SYSTEM INFORMATION\")\n","print('='*60)\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    print(f\"CUDA version: {torch.version.cuda}\")\n","print('='*60)"],"metadata":{"id":"check-gpu"},"execution_count":null,"outputs":[]}]}