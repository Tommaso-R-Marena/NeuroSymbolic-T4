{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# NeuroSymbolic-T4: ICML 2026 Benchmark Suite\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tommaso-R-Marena/NeuroSymbolic-T4/blob/main/notebooks/NeuroSymbolic_T4_Demo.ipynb)\n","[![Paper](https://img.shields.io/badge/ICML-2026-red.svg)](https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4)\n","\n","**Complete demonstration with publication-ready benchmarks on Google Colab T4 GPU**\n","\n","## Contents\n","\n","1. **Setup & Verification** - GPU check and installation\n","2. **System Initialization** - Load neurosymbolic model\n","3. **Neural Perception Demo** - Concept detection\n","4. **Symbolic Reasoning Demo** - Forward/backward chaining\n","5. **Query-Based Inference** - Proof generation\n","6. **Explanation Generation** - Interpretable AI\n","7. **Custom Rules** - Domain-specific knowledge\n","8. **Performance Benchmarking** - T4 GPU metrics\n","9. **ICML Benchmark Suite** - Comprehensive evaluation\n","10. **Ablation Study** - Component analysis\n","11. **Baseline Comparison** - SOTA models\n","12. **Results Visualization** - Publication figures\n","13. **Summary & Export** - Results for paper\n","\n","**New in this version**: Complete ICML benchmarking infrastructure with metrics, ablations, and visualizations."],"metadata":{"id":"title"}},{"cell_type":"markdown","source":["## 1. Setup and Installation"],"metadata":{"id":"setup-header"}},{"cell_type":"code","source":["# Verify T4 GPU\n","!nvidia-smi\n","\n","import torch\n","print(f\"\\n{'='*60}\")\n","print(\"SYSTEM INFORMATION\")\n","print('='*60)\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    print(f\"CUDA version: {torch.version.cuda}\")\n","print('='*60)"],"metadata":{"id":"check-gpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clone repository and install dependencies\n","!git clone https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4.git\n","%cd NeuroSymbolic-T4\n","\n","# Install all dependencies including benchmarking tools\n","!pip install -q -r requirements.txt\n","\n","print(\"\\nInstallation complete!\")\n","print(\"Installed: PyTorch, timm, sklearn, scipy, seaborn, matplotlib\")"],"metadata":{"id":"install"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Import and Initialize System"],"metadata":{"id":"import-header"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import time\n","import json\n","from pathlib import Path\n","\n","# Set style\n","sns.set_style(\"whitegrid\")\n","sns.set_context(\"notebook\")\n","plt.rcParams['figure.figsize'] = (10, 6)\n","\n","# Import neurosymbolic system\n","from neurosymbolic import NeurosymbolicSystem\n","from benchmarks.metrics import NeurosymbolicMetrics\n","\n","# Initialize system\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\\n\")\n","\n","model = NeurosymbolicSystem(\n","    perception_config={\n","        \"backbone\": \"efficientnet_b0\",\n","        \"feature_dim\": 512,\n","        \"num_concepts\": 100,\n","    }\n",").to(device)\n","\n","model.eval()\n","\n","# Initialize metrics\n","metrics_calculator = NeurosymbolicMetrics()\n","\n","print(\"Model initialized successfully!\")\n","print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")\n","print(f\"Concepts: {len(model.concept_names)}\")\n","print(f\"Rules: {len(model.reasoner.rules)}\")"],"metadata":{"id":"initialize"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Neural Perception Demo"],"metadata":{"id":"perception-header"}},{"cell_type":"code","source":["# Generate sample image\n","print(\"Generating sample image...\")\n","image = torch.randn(1, 3, 224, 224).to(device)\n","\n","# Perception\n","print(\"\\nRunning neural perception...\")\n","with torch.no_grad():\n","    perception_output = model.perceive(image, threshold=0.6)\n","\n","# Display detected concepts\n","symbolic_scene = perception_output[\"symbolic\"][0]\n","print(f\"\\nDetected {len(symbolic_scene)} concepts:\")\n","print(\"=\"*50)\n","\n","if symbolic_scene:\n","    # FIXED: Handle 3-tuple format (concept, confidence, grounded_name)\n","    for i, (concept, confidence, _) in enumerate(sorted(symbolic_scene, key=lambda x: x[1], reverse=True)[:10], 1):\n","        bar = '|' * int(confidence * 30)\n","        print(f\"{i:2d}. {concept:20s} {bar:30s} {confidence:.3f}\")\n","else:\n","    print(\"  No concepts detected above threshold\")\n","\n","print(\"=\"*50)"],"metadata":{"id":"perception-demo"},"execution_count":null,"outputs":[]}]}