{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NeuroSymbolic-T4: Complete Demo\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tommaso-R-Marena/NeuroSymbolic-T4/blob/main/notebooks/NeuroSymbolic_T4_Demo.ipynb)\n",
        "\n",
        "This notebook demonstrates the complete NeuroSymbolic-T4 system on Google Colab with T4 GPU.\n",
        "\n",
        "## Features Demonstrated:\n",
        "- Neural perception with concept grounding\n",
        "- Symbolic reasoning with forward/backward chaining\n",
        "- Query-based inference with explanations\n",
        "- Custom rule definition\n",
        "- Performance benchmarking on T4 GPU"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Installation"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify T4 GPU\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "check-gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4.git\n",
        "%cd NeuroSymbolic-T4\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "print(\"\\n✅ Installation complete!\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import and Initialize System"
      ],
      "metadata": {
        "id": "import-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from neurosymbolic import NeurosymbolicSystem\n",
        "import time\n",
        "\n",
        "# Initialize system\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = NeurosymbolicSystem(\n",
        "    perception_config={\n",
        "        \"backbone\": \"efficientnet_b0\",\n",
        "        \"feature_dim\": 512,\n",
        "        \"num_concepts\": 100,\n",
        "    }\n",
        ").to(device)\n",
        "\n",
        "model.eval()\n",
        "print(\"\\n✅ Model initialized successfully!\")"
      ],
      "metadata": {
        "id": "initialize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Neural Perception Demo"
      ],
      "metadata": {
        "id": "perception-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample image\n",
        "print(\"Generating sample image...\")\n",
        "image = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Perception\n",
        "print(\"\\nRunning neural perception...\")\n",
        "with torch.no_grad():\n",
        "    perception_output = model.perceive(image, threshold=0.6)\n",
        "\n",
        "# Display detected concepts\n",
        "symbolic_scene = perception_output[\"symbolic\"][0]\n",
        "print(f\"\\n✅ Detected {len(symbolic_scene)} concepts:\")\n",
        "\n",
        "if symbolic_scene:\n",
        "    for concept, confidence in sorted(symbolic_scene, key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"  {concept:20s}: {confidence:.3f}\")\n",
        "else:\n",
        "    print(\"  No concepts detected above threshold\")"
      ],
      "metadata": {
        "id": "perception-demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Symbolic Reasoning Demo"
      ],
      "metadata": {
        "id": "reasoning-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full forward pass (perception + reasoning)\n",
        "print(\"Running complete neurosymbolic pipeline...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.forward(image, threshold=0.6)\n",
        "\n",
        "reasoning = output[\"reasoning\"][0]\n",
        "print(f\"\\n✅ Derived {reasoning['num_derived']} new facts through reasoning\")\n",
        "\n",
        "if reasoning[\"derived_facts\"]:\n",
        "    print(\"\\nDerived facts:\")\n",
        "    for pred, args, conf in reasoning[\"derived_facts\"][:10]:\n",
        "        print(f\"  {pred}{args}: {conf:.3f}\")\n",
        "else:\n",
        "    print(\"\\nNo new facts derived (try lowering threshold or adding more rules)\")"
      ],
      "metadata": {
        "id": "reasoning-demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Query-Based Inference"
      ],
      "metadata": {
        "id": "query-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query: Is there something dangerous?\n",
        "query = (\"dangerous\", (\"obj0\",))\n",
        "\n",
        "print(f\"Query: {query[0]}{query[1]}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    proofs = model.query(image, query, threshold=0.5)\n",
        "\n",
        "print(f\"\\n✅ Found {len(proofs)} proof(s)\")\n",
        "\n",
        "if proofs:\n",
        "    print(\"\\nTop proof:\")\n",
        "    proof = proofs[0]\n",
        "    print(f\"Confidence: {proof['confidence']:.3f}\")\n",
        "    print(\"\\nProof steps:\")\n",
        "    for step in proof[\"proof\"]:\n",
        "        print(f\"  - {step}\")\n",
        "else:\n",
        "    print(\"\\nNo proofs found for this query\")"
      ],
      "metadata": {
        "id": "query-demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Explanation Generation"
      ],
      "metadata": {
        "id": "explanation-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate explanation for a fact\n",
        "fact_to_explain = (\"vehicle\", (\"obj0\",))\n",
        "\n",
        "print(f\"Explaining: {fact_to_explain[0]}{fact_to_explain[1]}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    explanations = model.explain_prediction(image, fact_to_explain, threshold=0.5)\n",
        "\n",
        "print(f\"\\n✅ Generated {len(explanations)} explanation(s)\")\n",
        "\n",
        "if explanations:\n",
        "    print(\"\\n\" + explanations[0])\n",
        "else:\n",
        "    print(\"\\nNo explanation found (fact may not hold for this input)\")"
      ],
      "metadata": {
        "id": "explanation-demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Custom Rules"
      ],
      "metadata": {
        "id": "custom-rules-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom domain rules\n",
        "print(\"Adding custom rules...\")\n",
        "\n",
        "# Rule 1: Large + Red = Important\n",
        "model.reasoner.add_rule(\n",
        "    head=(\"important\", (\"?x\",)),\n",
        "    body=[(\"large\", (\"?x\",)), (\"red\", (\"?x\",))],\n",
        "    confidence=0.9\n",
        ")\n",
        "print(\"  ✓ Rule: important(X) :- large(X) AND red(X) [0.9]\")\n",
        "\n",
        "# Rule 2: Important + Urgent = Priority\n",
        "model.reasoner.add_rule(\n",
        "    head=(\"priority\", (\"?x\",)),\n",
        "    body=[(\"important\", (\"?x\",)), (\"urgent\", (\"?x\",))],\n",
        "    confidence=0.95\n",
        ")\n",
        "print(\"  ✓ Rule: priority(X) :- important(X) AND urgent(X) [0.95]\")\n",
        "\n",
        "# Add test facts\n",
        "model.reasoner.add_fact(\"large\", (\"test_obj\",), 0.9)\n",
        "model.reasoner.add_fact(\"red\", (\"test_obj\",), 0.85)\n",
        "model.reasoner.add_fact(\"urgent\", (\"test_obj\",), 0.8)\n",
        "\n",
        "# Forward chain\n",
        "num_derived = model.reasoner.forward_chain()\n",
        "print(f\"\\n✅ Derived {num_derived} new facts\\n\")\n",
        "\n",
        "# Check derived facts\n",
        "important_conf = model.reasoner.query(\"important\", (\"test_obj\",))\n",
        "priority_conf = model.reasoner.query(\"priority\", (\"test_obj\",))\n",
        "\n",
        "if important_conf:\n",
        "    print(f\"important(test_obj): {important_conf:.3f}\")\n",
        "if priority_conf:\n",
        "    print(f\"priority(test_obj): {priority_conf:.3f}\")"
      ],
      "metadata": {
        "id": "custom-rules-demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Performance Benchmarking"
      ],
      "metadata": {
        "id": "benchmark-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Benchmarking inference speed on T4 GPU...\")\n",
        "\n",
        "# Warmup\n",
        "for _ in range(10):\n",
        "    x = torch.randn(1, 3, 224, 224).to(device)\n",
        "    with torch.no_grad():\n",
        "        _ = model.forward(x)\n",
        "\n",
        "# Benchmark\n",
        "torch.cuda.synchronize()\n",
        "times = []\n",
        "\n",
        "num_iterations = 100\n",
        "for i in range(num_iterations):\n",
        "    x = torch.randn(1, 3, 224, 224).to(device)\n",
        "    \n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        _ = model.forward(x)\n",
        "    torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    \n",
        "    times.append(end - start)\n",
        "    \n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f\"  Progress: {i + 1}/{num_iterations}\")\n",
        "\n",
        "# Statistics\n",
        "mean_time = np.mean(times) * 1000\n",
        "std_time = np.std(times) * 1000\n",
        "fps = 1.0 / np.mean(times)\n",
        "\n",
        "print(f\"\\n✅ Benchmark Results (T4 GPU):\")\n",
        "print(f\"  Mean latency: {mean_time:.2f} ± {std_time:.2f} ms\")\n",
        "print(f\"  Throughput: {fps:.1f} FPS\")\n",
        "print(f\"  GPU Memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "benchmark"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Run All Examples"
      ],
      "metadata": {
        "id": "examples-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run provided examples\n",
        "print(\"Running all provided examples...\\n\")\n",
        "\n",
        "!python examples/basic_usage.py"
      ],
      "metadata": {
        "id": "run-examples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "✅ Neural perception with EfficientNet backbone\n",
        "✅ Symbolic reasoning with forward/backward chaining\n",
        "✅ Query-based inference with proof generation\n",
        "✅ Explanation generation for predictions\n",
        "✅ Custom rule definition and integration\n",
        "✅ Performance benchmarking on T4 GPU\n",
        "\n",
        "**Expected Performance:**\n",
        "- Latency: ~20-30ms per image\n",
        "- Throughput: ~40-50 FPS\n",
        "- Memory: ~2-3 GB VRAM\n",
        "\n",
        "**Next Steps:**\n",
        "- Train on custom dataset\n",
        "- Add domain-specific rules\n",
        "- Integrate with real applications\n",
        "- Explore multi-object scenes\n",
        "\n",
        "For more information, visit: [GitHub Repository](https://github.com/Tommaso-R-Marena/NeuroSymbolic-T4)"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}